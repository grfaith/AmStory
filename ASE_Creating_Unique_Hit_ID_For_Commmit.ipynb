{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1351b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###  This code is to search through cleaned OCR recognized text for the string 'explore'\n",
    "#  The code will return one row for each hit with a unique ID based on the article_ID and location of the hit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3e4d958",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "working_dir = os.getcwd()+\"\\\\\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd5eaa33",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Getting files from disk\n",
    "\n",
    "# Getting file with hits and cleaned text\n",
    "hit_file_path = working_dir+'AM_Prox_SW_OCR_Concat.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "hit_df = pd.read_csv(hit_file_path)\n",
    "\n",
    "# Getting kw_file\n",
    "kw_file_path = working_dir+'AS_Explore_KW_String_and_Word.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "kw_df = pd.read_csv(kw_file_path, names=['keyword', 'kw_year', 'kw_type'], header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "863c8112",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Grouping multiple hits\n",
    "\n",
    "# Dropping column 'keyword_hit'\n",
    "if 'keyword_hit' in hit_df.columns:\n",
    "    hit_df.drop(columns=['keyword_hit'], inplace=True)\n",
    "else:\n",
    "    print(\"Warning: 'keyword_hit' column not found, skipping drop operation.\")\n",
    "\n",
    "# Dropping duplicate rows\n",
    "hit_df = hit_df.drop_duplicates()\n",
    "\n",
    "# Reindexing df\n",
    "hit_df.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db58880d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generates filtered KW df based on a year\n",
    "\n",
    "def get_filter_kw(search_year, kw_df):\n",
    "    \"\"\"\n",
    "    Filters a DataFrame of keywords based on a specified year.\n",
    "\n",
    "    Parameters:\n",
    "    - search_year (int): The year to filter by.\n",
    "    - kw_df (pandas.DataFrame): DataFrame containing keyword data with a column 'kwyear'.\n",
    "\n",
    "    Returns:\n",
    "    - pandas.DataFrame: Filtered DataFrame containing keywords where 'kwyear' <= search_year.\n",
    "    \"\"\"\n",
    "    # Convert search_year to integer\n",
    "    dataset_year = int(search_year)\n",
    "\n",
    "    # Filter the DataFrame based on the condition\n",
    "    kw_df_filtered = kw_df[kw_df['kw_year'] <= dataset_year]\n",
    "\n",
    "    return kw_df_filtered\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4f35b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function to find cases where 'explor' is within kw_dist of a keyword\n",
    "\n",
    "def find_explor_near_keywords(hit_df, kw_df, kw_dist=150):\n",
    "    \"\"\"\n",
    "    Function to find instances where the string 'explor' appears within 150 words of keywords,\n",
    "    considering different search modes ('string' or 'word') based on 'kw_type' in kw_filter_df.\n",
    "\n",
    "    Parameters:\n",
    "    - hit_df (pandas.DataFrame): DataFrame containing article data with columns 'article_ID' and 'article_year'.\n",
    "    - kw_df (pandas.DataFrame): DataFrame containing keyword data with columns 'keyword', 'kw_type', and 'kw_year'.\n",
    "    - kw_dist (int): Maximum distance in words within which to search for 'explor' near keywords. Default is 150.\n",
    "\n",
    "    Returns:\n",
    "    - result_df (pandas.DataFrame): DataFrame containing locations of 'explor' near keywords.\n",
    "    \"\"\"\n",
    "    result_dfs = []\n",
    "    \n",
    "    for index, row in hit_df.iterrows():\n",
    "        article_year = row['article_year']\n",
    "        \n",
    "        # Assuming get_filter_kw is defined elsewhere and used here to filter keywords\n",
    "        filtered_kw_df = get_filter_kw(article_year, kw_df)\n",
    "        \n",
    "        article_text = row['article']\n",
    "        article_lower = article_text.lower()  # Convert article text to lowercase for case-insensitive search\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        for kw_index, kw_row in filtered_kw_df.iterrows():\n",
    "            keyword = kw_row['keyword'].lower()  # Convert keyword to lowercase\n",
    "            \n",
    "            # Determine search mode based on 'kw_type'\n",
    "            kw_type = kw_row['kw_type']\n",
    "            if kw_type == 'string':\n",
    "                # Find keyword in the article text as substring using regex\n",
    "                keyword_positions = [m.start() for m in re.finditer(re.escape(keyword), article_lower)]\n",
    "            elif kw_type == 'word':\n",
    "                # Find keyword in the article text as whole word using regex\n",
    "                keyword_positions = [m.start() for m in re.finditer(r'\\b{}\\b'.format(re.escape(keyword)), article_lower)]\n",
    "            else:\n",
    "                raise ValueError(f\"Invalid kw_type '{kw_type}' for keyword '{keyword}'. Must be 'string' or 'word'.\")\n",
    "            \n",
    "            for kw_position in keyword_positions:\n",
    "                # Check if 'explor' is within kw_dist words of the keyword\n",
    "                explor_positions = [m.start() for m in re.finditer(r'explor', article_lower[max(0, kw_position - kw_dist): min(len(article_lower), kw_position + kw_dist)])]\n",
    "                \n",
    "                if explor_positions:\n",
    "                    for explor_position in explor_positions:\n",
    "                        results.append({\n",
    "                            'article_ID': row['article_ID'],\n",
    "                            'article_year': article_year,\n",
    "                            'article': row['article'],\n",
    "                            'keyword': kw_row['keyword'],\n",
    "                            'explor_position': explor_position + max(0, kw_position - kw_dist)  # Adjust position to the original text\n",
    "                        })\n",
    "        \n",
    "        # Convert results list to DataFrame and append to result_dfs\n",
    "        if results:\n",
    "            result_dfs.append(pd.DataFrame(results))\n",
    "    \n",
    "    # Concatenate all DataFrames in result_dfs\n",
    "    if result_dfs:\n",
    "        result_df = pd.concat(result_dfs, ignore_index=True)\n",
    "    else:\n",
    "        result_df = pd.DataFrame(columns=['article_ID', 'article_year', 'article', 'keyword', 'explor_position'])\n",
    "    \n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b4b73c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = find_explor_near_keywords(hit_df, kw_df, kw_dist=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d01783ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming result_df is already populated from running find_explor_near_keywords\n",
    "result_df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Optionally, reset index if needed\n",
    "result_df.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4483404a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming result_df is already populated and duplicates are removed\n",
    "# Group by 'article_ID' and 'explor_position', aggregate 'keyword' values\n",
    "combined_df = result_df.groupby(['article_ID', 'explor_position'], as_index=False)['keyword'].agg(lambda x: ', '.join(x))\n",
    "\n",
    "# Optionally, include other columns if needed\n",
    "combined_df = result_df.groupby(['article_ID', 'explor_position'], as_index=False).agg({\n",
    "    'keyword': lambda x: ', '.join(x),\n",
    "    'article_year': 'first',  # Assuming article_year is the same for grouped rows\n",
    "    'article': 'first'  # Assuming article text is the same for grouped rows\n",
    "})\n",
    "\n",
    "# Sort by 'article_year' if it exists\n",
    "if 'article_year' in combined_df.columns:\n",
    "    combined_df = combined_df.sort_values(by='article_year')\n",
    "\n",
    "# Reset index\n",
    "combined_df.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "68f7f12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv('ASEx_Unique_Hits.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
