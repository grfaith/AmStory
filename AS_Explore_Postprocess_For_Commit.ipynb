{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  This code runs the light processing routines from American Stories on AS-format article text.\n",
    "###  The file is loaded and saved locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installs\n",
    "\n",
    "!pip install symspellpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fy1ZCAu_twkf"
   },
   "outputs": [],
   "source": [
    "#Imports\n",
    "import io\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import tqdm as tq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FiTP4yy1c9oj",
    "outputId": "fbf74605-21f1-4b05-e0aa-95b6970bb688"
   },
   "outputs": [],
   "source": [
    "# let's initialize the package\n",
    "import pkg_resources\n",
    "from symspellpy import SymSpell, Verbosity\n",
    "import string\n",
    "\n",
    "sym_spell = SymSpell(max_dictionary_edit_distance=2, prefix_length=7)\n",
    "en_dict = pkg_resources.resource_filename('symspellpy', 'frequency_dictionary_en_82_765.txt')\n",
    "sym_spell.load_dictionary(en_dict, term_index=0, count_index=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tzFljHkyc-fb"
   },
   "outputs": [],
   "source": [
    "# This is code from AS and has functions for text correction and polishing.\n",
    "# we now create a few functions that take care of the issues flagged above\n",
    "\n",
    "# thsese two functions implement spelling corrections\n",
    "def check_word(word):\n",
    "  no_punc_word = word.strip(string.punctuation)\n",
    "  if len(no_punc_word) > 0:\n",
    "    suggestions = sym_spell.lookup(no_punc_word, Verbosity.CLOSEST, max_edit_distance=1, include_unknown=True, transfer_casing=True)\n",
    "  else:\n",
    "    return word\n",
    "  return word.replace(no_punc_word, suggestions[0].term)\n",
    "\n",
    "def spell_check(text):\n",
    "  lines = text.split('\\n')\n",
    "  checked_lines = []\n",
    "  for line in lines:\n",
    "    words = line.split(' ')\n",
    "    checked_line = ' '.join([check_word(word) for word in words])\n",
    "    checked_lines.append(checked_line)\n",
    "  return '\\n'.join(checked_lines)\n",
    "\n",
    "# this function checks capitalization\n",
    "def capitalization_check(text):\n",
    "  lines = text.split('\\n')\n",
    "  checked_lines = []\n",
    "  for line in lines:\n",
    "    words = line.split(' ')\n",
    "    for i in range(1, len(words)):\n",
    "      if words[i-1][-1] in ['.', '!', '?']:\n",
    "        words[i] = words[i].capitalize()\n",
    "      else:\n",
    "        no_punc_word = words[i].strip(string.punctuation)\n",
    "        if no_punc_word in sym_spell.words and no_punc_word not in ['i', \"i'll\"]: # Check that the word is not a propper noun\n",
    "          words[i] = words[i].replace(no_punc_word, no_punc_word.lower())\n",
    "\n",
    "    checked_lines.append(' '.join(words))\n",
    "  return '\\n'.join(checked_lines)\n",
    "\n",
    "# this functions corrects line breaks\n",
    "def line_merge(text):\n",
    "  lines = [l.split() for l in text.split('\\n')]\n",
    "  for i in range(len(lines) - 1):\n",
    "    if len(lines[i]) == 0 or len(lines[i+1]) == 0:\n",
    "      continue\n",
    "    elif lines[i][-1][-1] == '-': # Automatically merge if a line ends with a hyphen\n",
    "      lines[i][-1] = lines[i][-1][:-1] + lines[i+1][0]\n",
    "      lines[i+1] = lines[i+1][1:]\n",
    "    elif lines[i][-1].strip(string.punctuation).lower() not in sym_spell.words or lines[i+1][0].strip(string.punctuation).lower() not in sym_spell.words:\n",
    "      if (lines[i][-1].strip(string.punctuation).lower() + lines[i+1][0].strip(string.punctuation).lower()) in sym_spell.words:\n",
    "        lines[i][-1] += lines[i+1][0]\n",
    "        lines[i+1] = lines[i+1][1:]\n",
    "\n",
    "  return '\\n'.join([' '.join(l) for l in lines])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2nbl3M3AdSW9"
   },
   "outputs": [],
   "source": [
    "# this functions implements all three methods\n",
    "def postprocess(text):\n",
    "  merged = line_merge(text)\n",
    "  checked = spell_check(merged)\n",
    "  capitalization_normalized = capitalization_check(checked)\n",
    "  return capitalization_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loading csv file into memory\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# File name\n",
    "file_name = \"AS_Explor_Prox_Concat_Grouped.csv\"\n",
    "\n",
    "# File path\n",
    "file_path = os.path.join(current_directory, file_name)\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(file_path):\n",
    "    # Load the CSV file into a DataFrame\n",
    "    kw_hit_grouped_df = pd.read_csv(file_path)\n",
    "    print(\"File loaded successfully.\")\n",
    "    # Now you can work with the DataFrame 'df'\n",
    "else:\n",
    "    print(f\"Error: File '{file_name}' not found in the current directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applies postprocess function to kw_hit_grouped_df\n",
    "\n",
    "# Define a function to track progress\n",
    "def track_progress(iterable, prefix='', suffix='', decimals=1, length=100, fill='â–ˆ'):\n",
    "    total = len(iterable)\n",
    "    def print_progress(iteration):\n",
    "        percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n",
    "        filled_length = int(length * iteration // total)\n",
    "        bar = fill * filled_length + '-' * (length - filled_length)\n",
    "        print(f'\\r{prefix} |{bar}| {percent}% {suffix}', end='\\r')\n",
    "        if iteration == total:\n",
    "            print()\n",
    "    return print_progress\n",
    "\n",
    "# Define a function to apply postprocess to each element in the 'article' column\n",
    "def apply_postprocess(article):\n",
    "    # Track progress\n",
    "    apply_postprocess.counter += 1\n",
    "    progress_tracker(apply_postprocess.counter)\n",
    "    # Apply postprocess function to the element\n",
    "    return postprocess(article)\n",
    "\n",
    "# Initialize a counter\n",
    "apply_postprocess.counter = 0\n",
    "\n",
    "# Create a progress tracker\n",
    "progress_tracker = track_progress(range(len(kw_hit_grouped_df['article'])), prefix='Progress:', suffix='Complete', length=50)\n",
    "\n",
    "# Apply the function to the 'article' column\n",
    "kw_hit_grouped_df['article'] = kw_hit_grouped_df['article'].apply(apply_postprocess)\n",
    "\n",
    "print (\"Finished!  Don't forget to save dataframe to csv!  It's in the next cell.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file in the local working directory\n",
    "kw_hit_grouped_df.to_csv('kw_grouped_postprocess.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(kw_hit_grouped_df)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
